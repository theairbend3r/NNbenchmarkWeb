<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8"/>
<style>body{background-color:white;}</style>
<script src="lib/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="lib/bootstrap-3.3.5/css/simplex.min.css" rel="stylesheet" />
<script src="lib/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="lib/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="lib/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="lib/kePrint-0.0.1/kePrint.js"></script>

</head>
<body>
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:center;"> Id </th>
   <th style="text-align:center;"> Package </th>
   <th style="text-align:center;"> Category </th>
   <th style="text-align:center;"> Reason to Discard </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;"> 1 </td>
   <td style="text-align:center;"> appnn </td>
   <td style="text-align:center;"> AP </td>
   <td style="text-align:center;"> Provide a feed forward neural network to predict the amyloidogenicity propensity of polypeptide sequences (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 2 </td>
   <td style="text-align:center;"> autoencoder </td>
   <td style="text-align:center;"> AP </td>
   <td style="text-align:center;"> Provide a sparse autoencoder, an unsupervised algorithm that learns useful features from the data its given (::autoencode) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 3 </td>
   <td style="text-align:center;"> BNN </td>
   <td style="text-align:center;"> RE* </td>
   <td style="text-align:center;"> Use a feed forward neural network to perform regression. It is unclear whether it fits the form of perceptron in the scope. It states that it is intended for variable selection, although how exactly the package would be used to do so is missing. Also the source code is written in C that users of R might not understand. Performance is slow : need 100.000 iterations. (::BNNsel-examples &amp; abstract of paper) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 4 </td>
   <td style="text-align:center;"> Buddle </td>
   <td style="text-align:center;"> CL </td>
   <td style="text-align:center;"> Did not include regression in 2019. Unfortunately, the version we tested in 2020 could not be used properly for regression either. See the examples (::TrainBuddle) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 5 </td>
   <td style="text-align:center;"> cld2 </td>
   <td style="text-align:center;"> XX </td>
   <td style="text-align:center;"> Provide bindings to Google's C++ library CLD2, which detects languages using a Naïve Bayesian classifier. CLD3, which does use neural networks, is mentioned in the description (DESCRIPTION file &amp; link to github) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 6 </td>
   <td style="text-align:center;"> cld3 </td>
   <td style="text-align:center;"> AP </td>
   <td style="text-align:center;"> Bindings to Google's C++ library CLD3, which detects languages using a neural network with an experimental algorithm (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 7 </td>
   <td style="text-align:center;"> condmixt </td>
   <td style="text-align:center;"> AP </td>
   <td style="text-align:center;"> Use neural networks to predict parameters of mixture models (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 8 </td>
   <td style="text-align:center;"> DamiaNN </td>
   <td style="text-align:center;"> RE </td>
   <td style="text-align:center;"> Was designed specificly for training datasets from Numerai, &lt;https://numer.ai/&gt;. We were unable to adapt it to our datasets even after exporting functions from the interactive interface (DESCRIPTION file, help pages) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 9 </td>
   <td style="text-align:center;"> deep </td>
   <td style="text-align:center;"> CL </td>
   <td style="text-align:center;"> Seem to implement a perceptron to classify data (implicitly known from choice of iris as example and in source code) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 10 </td>
   <td style="text-align:center;"> deepNN </td>
   <td style="text-align:center;"> RE </td>
   <td style="text-align:center;"> Another implementation of deep learning. Its input format of lists of vectors is not standard require users to understand how to use lapply or other functions to convert the format of their data. Univariate datasets can't be used with the functions and we could not manage to adapt it to 2020 code (::train). </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 11 </td>
   <td style="text-align:center;"> DNMF </td>
   <td style="text-align:center;"> XX </td>
   <td style="text-align:center;"> Help extract features that enforce spatial locality with separability between classes in a discriminant manner (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 12 </td>
   <td style="text-align:center;"> evclass </td>
   <td style="text-align:center;"> CL </td>
   <td style="text-align:center;"> Provide an evidential neural network that outputs Dempster-Shafer mass functions (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 13 </td>
   <td style="text-align:center;"> gamlss.add </td>
   <td style="text-align:center;"> UT </td>
   <td style="text-align:center;"> Allow users to use nnet with a variety of Generalized Additive Models for Location Scale and Shape (::nn). It is not particularly appropriate for all our datasets. </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 14 </td>
   <td style="text-align:center;"> gcForest </td>
   <td style="text-align:center;"> XX </td>
   <td style="text-align:center;"> Based on an article with "Towards an Alternative to Deep Neural Networks" in its title (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 15 </td>
   <td style="text-align:center;"> GMDH </td>
   <td style="text-align:center;"> TS </td>
   <td style="text-align:center;"> Provide GMDH type neural network algorithms for short term forecasting on a univariate time series (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 16 </td>
   <td style="text-align:center;"> GMDH2 </td>
   <td style="text-align:center;"> CL </td>
   <td style="text-align:center;"> Provide GMDH type neural network algorithms for performing binary classification (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 17 </td>
   <td style="text-align:center;"> GMDHreg </td>
   <td style="text-align:center;"> RE* </td>
   <td style="text-align:center;"> Regression using GMDH algorithms. We only managed to tested the COMBI algorithm (the most basic and first in the vignette) on the multivariate datasets. It is strangely slow on the "easy" datasets, mFriedman and mRef153. The convergence is relatively not good considering the ammount of layers (Title in DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 18 </td>
   <td style="text-align:center;"> gnn </td>
   <td style="text-align:center;"> AP </td>
   <td style="text-align:center;"> Out of scope: Generative moment matching networks (GMMNs) are introduced for generating quasi-random samples from multivariate models (article abstract) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 19 </td>
   <td style="text-align:center;"> grnn </td>
   <td style="text-align:center;"> RE </td>
   <td style="text-align:center;"> Provide an implementation of Specht's General Regression Neural Network in 1991 (DESCRIPTION file). We could not manage to make the functions work on the multivariate datasets. ::guess, the function for predicting, only allows for 1 data at a time. Performance of General Regression Neural Networks can be seen from package yager instead. </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 20 </td>
   <td style="text-align:center;"> hybridEnsemble </td>
   <td style="text-align:center;"> RE </td>
   <td style="text-align:center;"> Hybrid ensemble of eight different sub-ensembles (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 21 </td>
   <td style="text-align:center;"> image.libfacedetection </td>
   <td style="text-align:center;"> AP </td>
   <td style="text-align:center;"> Face detection with CNNs (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 22 </td>
   <td style="text-align:center;"> isingLenzMC </td>
   <td style="text-align:center;"> AP </td>
   <td style="text-align:center;"> Out of scope: This package provides utilities to simulate one dimensional Ising Model with Metropolis and Glauber Monte Carlo (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 23 </td>
   <td style="text-align:center;"> kerasR </td>
   <td style="text-align:center;"> RE </td>
   <td style="text-align:center;"> See section on keras </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 24 </td>
   <td style="text-align:center;"> leabRa </td>
   <td style="text-align:center;"> RE </td>
   <td style="text-align:center;"> Provide the local error driven and associative biologically realistic algorithm (Leabra) from O'Reilly 1996. It combines supervised and unsupervised learning, so out of scope (DESCRIPTION file). </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 25 </td>
   <td style="text-align:center;"> learNN </td>
   <td style="text-align:center;"> CL </td>
   <td style="text-align:center;"> Implement some basic neural networks from \url{http://qua.st/} (DESCRIPTION file). Examples seem to focus on binary classification (::learn_gd, ::learn_bp). </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 26 </td>
   <td style="text-align:center;"> LilRhino </td>
   <td style="text-align:center;"> AP </td>
   <td style="text-align:center;"> Provide binary neural networks meant for reducing data (DESCRIPTION file), a random forest style collection of neural networks for classification (::Random_Brains), and code for even more purposes. Documentation is satisfyingly clear for a package for applications: a 3 layer network with an adam optimizer, with an explanation of its activation functions (::Binary_Network) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 27 </td>
   <td style="text-align:center;"> neural </td>
   <td style="text-align:center;"> CL </td>
   <td style="text-align:center;"> An implementation of "a simple MLP neural network that is suitable for classification tasks" (::mlptrain) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 28 </td>
   <td style="text-align:center;"> NeuralNetTools </td>
   <td style="text-align:center;"> UT </td>
   <td style="text-align:center;"> Out of scope: Functions are available for plotting, quantifying variable importance, conducting a sensitivity analysis, and obtaining a simple list of model weights (DESCRIPTION file and Help Pages titles) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 29 </td>
   <td style="text-align:center;"> NeuralSens </td>
   <td style="text-align:center;"> UT </td>
   <td style="text-align:center;"> A greater focus on sensitivity, with additional functions (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 30 </td>
   <td style="text-align:center;"> NlinTS </td>
   <td style="text-align:center;"> TS </td>
   <td style="text-align:center;"> A non-linear version of a causality test with feed forward neural networks and a Vector Auto-Regressive Neural Network (VARNN) for non-linear time series analysis models (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 31 </td>
   <td style="text-align:center;"> nnetpredint </td>
   <td style="text-align:center;"> UT </td>
   <td style="text-align:center;"> Out of scope: Computing prediction intervals of neural network models at certain confidence level (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 32 </td>
   <td style="text-align:center;"> nnfor </td>
   <td style="text-align:center;"> TS </td>
   <td style="text-align:center;"> Automatic to fully manual time series modelling with neural networks (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 33 </td>
   <td style="text-align:center;"> nnlib2Rcpp </td>
   <td style="text-align:center;"> CL </td>
   <td style="text-align:center;"> Provide a collection of neural networks, but examples seem to indicate classification and testing our code with the functions provided led to error. Using the RcppClass might be confusing for less experienced R users (::NN-class) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 34 </td>
   <td style="text-align:center;"> nntrf </td>
   <td style="text-align:center;"> AP </td>
   <td style="text-align:center;"> Provide useful pre-processing for Machine Learning tasks through data transformation in a non-linear, supervised way with a perceptron (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 35 </td>
   <td style="text-align:center;"> onnx </td>
   <td style="text-align:center;"> UT </td>
   <td style="text-align:center;"> Aims to provide an open source format for neural networks, with definitions of an extensible computation graph model, built-in operators, and standard data types (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 36 </td>
   <td style="text-align:center;"> OptimClassifier </td>
   <td style="text-align:center;"> UT </td>
   <td style="text-align:center;"> Search for the best amount of neurons for binary classifcation neural networks, among other types of binary classifiers (based on how Optim.NN works &amp; DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 37 </td>
   <td style="text-align:center;"> OSTSC </td>
   <td style="text-align:center;"> UT </td>
   <td style="text-align:center;"> A tool to solve imbalanced data for univariate time series classification with oversampling using integrated ESPO and ADASYN methods (DESCRIPTION file) thus improving the performance of RNN classifiers (vignette) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 38 </td>
   <td style="text-align:center;"> passt </td>
   <td style="text-align:center;"> AP </td>
   <td style="text-align:center;"> This package provides implementation of the Probability Associator Time (PASS-T) model, a memory model based on a simple competitive artificial neural network which imitates human judgment of frequency and duration (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 39 </td>
   <td style="text-align:center;"> pnn </td>
   <td style="text-align:center;"> CL </td>
   <td style="text-align:center;"> This package provides implementation of the Specht algorithm, 1990, for classification with four functions: learn, smooth, perf, and guess (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 40 </td>
   <td style="text-align:center;"> polyreg </td>
   <td style="text-align:center;"> XX </td>
   <td style="text-align:center;"> Polyregression as alternative to NN (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 41 </td>
   <td style="text-align:center;"> predictoR </td>
   <td style="text-align:center;"> RE </td>
   <td style="text-align:center;"> A shiny interface for supervised learning with very minimal documentation. Users may be additionally confused when opening the application only to find that it's default language is Espanol, although this can be changed in the Idioma section. (DESCRIPTION file &amp; ::init_predictor) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 42 </td>
   <td style="text-align:center;"> ProcData </td>
   <td style="text-align:center;"> AP </td>
   <td style="text-align:center;"> Provide tools for exploratory process data analysis via functions: reading, process manipulation, action sequence generators, feature extraction and prediction (link + DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 43 </td>
   <td style="text-align:center;"> quarrint </td>
   <td style="text-align:center;"> AP </td>
   <td style="text-align:center;"> Out of scope: provide two indexes for interaction prediction between groundwater and quarry extension, one of which is an artificial neural network ; specified classifier for quarry data (help page - quarrint-package and DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 44 </td>
   <td style="text-align:center;"> rasclass </td>
   <td style="text-align:center;"> CL </td>
   <td style="text-align:center;"> Provide neural networks as one of the five supervised classification algorithms for raster images with a design meant to facilitate land-cover analysis (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 45 </td>
   <td style="text-align:center;"> rcane </td>
   <td style="text-align:center;"> RE </td>
   <td style="text-align:center;"> Provide parameter estimation for linear regression, which was not appropriate for the relationships in our data. (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 46 </td>
   <td style="text-align:center;"> regressoR </td>
   <td style="text-align:center;"> RE </td>
   <td style="text-align:center;"> A manual rich version of predictoR </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 47 </td>
   <td style="text-align:center;"> rnn </td>
   <td style="text-align:center;"> AP </td>
   <td style="text-align:center;"> Implementations of the vanilla Recurrent Neural Network, Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU) in native R (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 48 </td>
   <td style="text-align:center;"> RTextTools </td>
   <td style="text-align:center;"> AP </td>
   <td style="text-align:center;"> Out of scope: A machine learning package for automatic text classification (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 49 </td>
   <td style="text-align:center;"> ruta </td>
   <td style="text-align:center;"> AP </td>
   <td style="text-align:center;"> unsupervised neural networks (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 50 </td>
   <td style="text-align:center;"> simpleNeural </td>
   <td style="text-align:center;"> CL </td>
   <td style="text-align:center;"> Neural networks for multi-class or binary classification (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 51 </td>
   <td style="text-align:center;"> softmaxreg </td>
   <td style="text-align:center;"> CL </td>
   <td style="text-align:center;"> Out of scope: Implementation of 'softmax' regression and classification models with multiple layer neural network (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 52 </td>
   <td style="text-align:center;"> Sojourn.Data </td>
   <td style="text-align:center;"> AP </td>
   <td style="text-align:center;"> Stores some neural networks used for Sojourn Accelerometer methods (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 53 </td>
   <td style="text-align:center;"> spnn </td>
   <td style="text-align:center;"> CL </td>
   <td style="text-align:center;"> Out of scope : Scale invariant version of the original PNN with the added functionality of allowing for smoothing along multiple dimensions while accounting for covariances within the data set (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 54 </td>
   <td style="text-align:center;"> studyStrap </td>
   <td style="text-align:center;"> AP </td>
   <td style="text-align:center;"> Implements multi-study learning algorithms such as merging, the study-specific ensemble the study strap, the covariate-matched study strap, covariate-profile similarity weighting, and stacking weights with single-study learners from caret (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 55 </td>
   <td style="text-align:center;"> TeachNet </td>
   <td style="text-align:center;"> CL </td>
   <td style="text-align:center;"> Provide neural networks with up to 2 hidden layers, 2 different error functions, and a weight decay for 2 class classification : it is slow. (DESCRIPTION file &amp; ::TeachNet) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 56 </td>
   <td style="text-align:center;"> tensorflow </td>
   <td style="text-align:center;"> RE </td>
   <td style="text-align:center;"> See section on keras </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 57 </td>
   <td style="text-align:center;"> tfestimators </td>
   <td style="text-align:center;"> RE </td>
   <td style="text-align:center;"> See section on keras </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 58 </td>
   <td style="text-align:center;"> trackdem </td>
   <td style="text-align:center;"> AP </td>
   <td style="text-align:center;"> An artificial neural network can be trained for filtering false positives present in video materials or image sequences (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 59 </td>
   <td style="text-align:center;"> TrafficBDE </td>
   <td style="text-align:center;"> RE* </td>
   <td style="text-align:center;"> Use caret for a grid of parameters for 3 layers combined with neuralnet. Is very slow. Out of scope to test one layer perceptrons. We recommend the author to use other packages and lessen the number of layers. Datasets in Traffic Status Prediction and Urban Places are similar in nature to ours (TrainCR.R, DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 60 </td>
   <td style="text-align:center;"> tsfgrnn </td>
   <td style="text-align:center;"> TS </td>
   <td style="text-align:center;"> Out of scope: A general regression neural network (GRNN) is a variant of a Radial Basis Function Network. Allow you to forecast time series using an autoregressive GRNN model (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 61 </td>
   <td style="text-align:center;"> yager </td>
   <td style="text-align:center;"> RE* </td>
   <td style="text-align:center;"> This package provides a neural network that behaves differently from a perceptron. Results indicate that predictions are quite close to the real values, however this comes at the cost of a large number of weights. With less weights or insufficient training data, the performance isn't as great. (::grnn.fit) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 62 </td>
   <td style="text-align:center;"> yap </td>
   <td style="text-align:center;"> CL </td>
   <td style="text-align:center;"> Yet another PNN, with a N-level response, where N &gt; 2 (DESCRIPTION file) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 63 </td>
   <td style="text-align:center;"> zFactor </td>
   <td style="text-align:center;"> AP </td>
   <td style="text-align:center;"> Computational algorithms to solve equations and find the 'compressibility' factor `z` of hydrocarbon gases (DESCRIPTION file) </td>
  </tr>
</tbody>
</table>
</body>
</html>
